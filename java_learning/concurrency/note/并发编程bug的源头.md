## 前言
cpu,内存,I/O设备都在不断的迭代，不断朝着更快的方向努力，但是，在这个快速发展的过程中，有一个核心矛盾一直存在，就是这三者的速度差异。cpu > 内存 > i/0。根据木桶理论，程序整体的性能取决于最慢的操作-i/o设备的读写，也就是说单方面提高cpu性能是无效的。
为了平衡这三者的速度差异，计算机体系机构，操作系统，编译程序都做出了贡献，主要体现在：
1. cpu增加了缓存，以均衡与内存的速度差异；
2. 操作系统增加了进程，线程，以分时复用cpu,进而均衡cpu与i/o设备的速度差异；
3. 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。

## 缓存导致的可见性问题
在单核时代，所有的线程都在一颗cpu上运行，cpu缓存与内存的数据一致性容易解决，因为所有线程都操作同一颗cpu的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。
一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称之为**可见性**。

在多核时代，每颗cpu都有自己的缓存，这时cpu缓存与内存的数据一致性就没那么容易解决了。当多个线程在不同的cpu上运行时，这些线程操作的是不同的cpu缓存。假设线程a在cpu-1上运行，线程b在CPU-2上运行，此时线程a对变量v的操作对线程b来说是不可见的。

```java
public class Test{
    private long count = 0;
    private void add(){
        int i = 0;
        while(i++ <= 10000){
            count += 1;
        }
    }
    
    public static long calc(){
        final Test test = new Test();
        Thread t1 = new Thread(()->{
            test.add();
        });
        
        Thread t2 = new Thread(()->{
            test.add();
        });
        
        t1.start();
        t2.start();
        
        t1.join();
        t2.join();
        retun count;
    }
}
```

上面的程序，如果在单核时代，那么结果毋庸置疑是20000，但在多核时代，最后结果是10000-20000之间的随机数。
我们假设t1和t2线程同时开始执行，那么第一次都会将count=0读到各自的cpu缓存里，执行完count += 1之后，各自的cpu缓存里的值都是1，而不是我们期望的2.之后由于各自的cpu缓存里都有count值，所以导致最终count的计算结果小于20000.这就是缓存的可见性问题。

## 线程切换-原子性问题
我们电脑里可以开着网易云听音乐的同时，你还能打开ide工具，写bug，这就是多进程的功劳，进程与进程之间可以进行任务的切换，切换的时间间隔，我们称为“时间片“。

在一个时间片内，如果一个进程进行一个io操作，例如读取文件，这个时候该进程可以把自己标记为“休眠状态”并出让cpu使用权，代文件读进内存后，操作系统就会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得cpu的使用权。出让cpu的使用权，可以让cpu做其他事，这样cpu的利用率就上来了。那么如果有另外一个进程也要读取文件，读文件的操作就会排队，磁盘驱动在完成一个进程的读操作后，发现有排队的任务，就会立即启动下一个读操作，这样io的利用率也上来了。

java并发程序都是基于多线程的，这样也会涉及到线程切换。执行count += 1的操作，至少需要三条cpu指令：
1. 首先，需要把变量count 从内存中加载到cpu的寄存器。
2. 在寄存器中执行 +1 操作。
3. 将结果写入内存，缓存机制导致可能写入的是cpu的缓存还不是内存。

对于上面的三个指令来说，如果线程a刚刚执行完指令1，就和线程b发生了线程切换，导致count的值还是为0，而不是+1之后的值，就会导致其结果不是我们希望的2.

我们把一个或者多个操作在cpu执行的过程中不被中断的特性称为原子性。

## 编译优化-有序性问题
有序性指的是程序按照代码的先后顺序执行。
但是编译器为了优化性能，有时候会改变程序中语句的先后顺序。例如程序：“a = 6; b = 7”，编译优化后的顺序可能为：”b=7;a=6;“。
java中最经典的案例就是单例模式，利用双重检查创建单例对象，保证线程安全。
```java
public class Singleton{
    static Singleton bean;
    static Singleton getInstance(){
        if(bean == null){
            synchronized(Singleton.class){
                if(bean == null){
                    bean = new Singleton();
                }
            }
        }
        return bean;
    }
}
```
假设有两个线程a b同时调用getInstance()方法，于是同时对Singleton.class加锁，此时jvm保证只有一个线程能够加锁成功，假设是a，那么b就会处于等待状态，当a执行完，释放锁之后，B被唤醒，继续执行，发现已经有bean对象，所以直接return了。我们以为jvm创建对象的顺序是这样的：
1. 分配一块内存m;
2. 在内存m上初始化singleton对象；
3. 然后m的地址赋值给bean变量；

但是实际上优化后的执行路径是这样的：
1. 分配一块内存m；
2. 将m的地址赋值给bean变量；
3. 在内存M上初始化singleton对象；

当线程a先执行完getinstance()方法，当执行完指令2的时候，恰好发生了线程切换，切换到了线程b，如果此时线程B，也执行了getinstance方法，那么线程B在执行第一个判断的时候，就会发现bean!=null，直接return,如果这个时候我们访问bean对象的时候，就会报空指针异常。

## 总结
1. cpu缓存导致的可见性问题；
2. 线程切换带来的原子性问题；
3. 编译优化带来的有序性问题；